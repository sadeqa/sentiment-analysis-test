{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14632bce-a4b8-432f-ad68-10254649e6d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation with finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3745e23-87ba-4cf1-a8bf-cea9b92dc0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd \n",
    "from langdetect import detect, LangDetectException\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def detect_language(s):\n",
    "    try:\n",
    "        return detect(s)\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "# In here, put the path to the model in your machine\n",
    "state_dict = torch.load(\"sentiment-analysis-test/models/sentiment/model-epoch=9-val_loss=0.40.ckpt\")['state_dict']\n",
    "state_dict = {k.replace('process_model.',''):v for k,v in state_dict.items()}\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n",
    "model.load_state_dict(state_dict)\n",
    "del state_dict\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model.to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f102b624-c221-4260-840d-30adf9b096a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./sentiment-analysis-test/data/val_clean.csv\")\n",
    "test['lang'] = test['content'].apply(lambda x: detect_language(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "130aa5ab-b527-47d9-9984-c9e72b83e06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [01:50<00:00, 45.35it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for item in tqdm(test.values):\n",
    "    tokenized = tokenizer(item[0], return_tensors='pt',\n",
    "            max_length=256,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True)\n",
    "    if use_gpu:\n",
    "        tokenized = tokenized.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        out = model(**tokenized)\n",
    "    predictions.append(np.argmax(out.logits.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa3c10b-e610-4327-b8d7-e746120134f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_TO_ID = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "true_labels = [LABEL_TO_ID[item] for item in test['sentiment'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26ed4a97-7cc5-4ab4-b90d-6c70c5dfafc8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import pickle \n",
    "#with open('preds.pkl', 'wb') as f:\n",
    "#    pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77bc2a3a-bacb-4b16-9242-18a6cf011ee5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import pickle \n",
    "#with open('preds.pkl', 'rb') as f:\n",
    "#    predictions = pickle.load(f)\n",
    "#import pandas as pd \n",
    "#from langdetect import detect, LangDetectException\n",
    "#def detect_language(s):\n",
    "#    try:\n",
    "#        return detect(s)\n",
    "#    except LangDetectException:\n",
    "#        return \"unknown\"\n",
    "#test = pd.read_csv(\"./sentiment-analysis-test/data/val_clean.csv\")\n",
    "#test['lang'] = test['content'].apply(lambda x: detect_language(x))\n",
    "#LABEL_TO_ID = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "#true_labels = [LABEL_TO_ID[item] for item in test['sentiment'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f89988c-191f-49f7-8226-459f5f914f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.846\n",
      "Accucary for negative: 0.8109484404837684\n",
      "Accucary for neutral: 0.9031161473087819\n",
      "Accucary for positive: 0.8185096153846154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(f'Accuracy: {accuracy_score(true_labels, predictions)}')\n",
    "matrix = confusion_matrix(true_labels, predictions)\n",
    "acc_classes = matrix.diagonal()/matrix.sum(axis=1)\n",
    "for i in range(len(acc_classes)):\n",
    "    print(f\"Accucary for {list(LABEL_TO_ID.keys())[i]}: {acc_classes[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6998a86-82ba-4178-9a8a-cf64ee4e372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:00, 1233256.10it/s]\n"
     ]
    }
   ],
   "source": [
    "data_lang_dic = {}\n",
    "from tqdm import tqdm\n",
    "for i, item in tqdm(enumerate(test.values)):\n",
    "    if item[2] not in data_lang_dic.keys():\n",
    "        data_lang_dic[item[2]] = []\n",
    "    data_lang_dic[item[2]].append([item[0], item[1], predictions[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "104b16e4-c492-41b9-9a05-2e4fcd170bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_lang = []\n",
    "for k,v in data_lang_dic.items():\n",
    "    true_lab = [LABEL_TO_ID[item[1]] for item in v]\n",
    "    pred_lab = [item[2] for item in v]\n",
    "    matrix = confusion_matrix(true_lab, pred_lab)\n",
    "    #print(f\"For the language {k}: Accuracy is: {accuracy_score(true_lab, pred_lab)}\")\n",
    "    #print(f\"Accuracy per class is : {matrix.diagonal()/matrix.sum(axis=1)}\")\n",
    "    #print('---------------------------------------------------')\n",
    "    table_lang.append([k, accuracy_score(true_lab, pred_lab), matrix.diagonal()/matrix.sum(axis=1), len(v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8845d022-4429-4d34-bc46-5e86e62b7ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_lang_sorted = sorted(table_lang, key=lambda k: -k[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e225f0-cf1d-4bd8-8ad0-2b38bc17487b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>acc per class</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>0.814681</td>\n",
       "      <td>[0.7644787644787645, 0.87, 0.8014705882352942]</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ru</td>\n",
       "      <td>0.942161</td>\n",
       "      <td>[0.9069767441860465, 0.9826839826839827, 0.929...</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id</td>\n",
       "      <td>0.866455</td>\n",
       "      <td>[0.8564814814814815, 0.9508928571428571, 0.777...</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ar</td>\n",
       "      <td>0.850144</td>\n",
       "      <td>[0.8230088495575221, 0.9290780141843972, 0.763...</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr</td>\n",
       "      <td>0.850993</td>\n",
       "      <td>[0.8469387755102041, 0.8829787234042553, 0.827...</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>es</td>\n",
       "      <td>0.849817</td>\n",
       "      <td>[0.8181818181818182, 0.8571428571428571, 0.871...</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pt</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>[0.9012345679012346, 0.9090909090909091, 0.880...</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ko</td>\n",
       "      <td>0.760369</td>\n",
       "      <td>[0.813953488372093, 0.7272727272727273, 0.7733...</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zh-cn</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>[0.75, 0.65, 0.7586206896551724]</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ja</td>\n",
       "      <td>0.913580</td>\n",
       "      <td>[0.8518518518518519, 0.9583333333333334, 0.933...</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lang  accuracy                                      acc per class  size\n",
       "0     en  0.814681     [0.7644787644787645, 0.87, 0.8014705882352942]   831\n",
       "1     ru  0.942161  [0.9069767441860465, 0.9826839826839827, 0.929...   657\n",
       "2     id  0.866455  [0.8564814814814815, 0.9508928571428571, 0.777...   629\n",
       "3     ar  0.850144  [0.8230088495575221, 0.9290780141843972, 0.763...   347\n",
       "4     fr  0.850993  [0.8469387755102041, 0.8829787234042553, 0.827...   302\n",
       "5     es  0.849817  [0.8181818181818182, 0.8571428571428571, 0.871...   273\n",
       "6     pt  0.896104  [0.9012345679012346, 0.9090909090909091, 0.880...   231\n",
       "7     ko  0.760369  [0.813953488372093, 0.7272727272727273, 0.7733...   217\n",
       "8  zh-cn  0.720430                   [0.75, 0.65, 0.7586206896551724]   186\n",
       "9     ja  0.913580  [0.8518518518518519, 0.9583333333333334, 0.933...   162"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_acc_df = pd.DataFrame(table_lang_sorted, columns= [\"lang\", \"accuracy\", \"acc per class\", \"size\"])\n",
    "lang_acc_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00123121-a469-4353-b24b-c599fb8134a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_acc_df.to_csv(\"accuracy_per_language_pretrained.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
