{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "448b47c0-4d81-4eef-ab38-422ca1b8db1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation with finetuned model on augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "849a4e42-963e-4350-9b21-52456c195609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd \n",
    "from langdetect import detect, LangDetectException\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def detect_language(s):\n",
    "    try:\n",
    "        return detect(s)\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "# In here, put the path to the model in your machine\n",
    "state_dict = torch.load(\"sentiment-analysis-test/models/sentiment/model-epoch=9-val_loss=0.40.ckpt\")['state_dict']\n",
    "state_dict = {k.replace('process_model.',''):v for k,v in state_dict.items()}\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n",
    "model.load_state_dict(state_dict)\n",
    "del state_dict\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model.to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e68e71c1-34de-4e43-8e74-9c57006fa8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./sentiment-analysis-test/data/val_clean.csv\")\n",
    "test['lang'] = test['content'].apply(lambda x: detect_language(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16ec5f02-f713-4a94-9cd4-991ec6c60ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [01:51<00:00, 44.89it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for item in tqdm(test.values):\n",
    "    tokenized = tokenizer(item[0], return_tensors='pt',\n",
    "            max_length=256,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True)\n",
    "    if use_gpu:\n",
    "        tokenized = tokenized.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        out = model(**tokenized)\n",
    "    predictions.append(np.argmax(out.logits.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b239fdbf-787d-4f65-949f-50fe7db8bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_TO_ID = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "true_labels = [LABEL_TO_ID[item] for item in test['sentiment'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac932127-eaae-4fd5-8012-567b715dea57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import pickle \n",
    "#with open('preds_finetuned_augmented.pkl', 'wb') as f:\n",
    "#    pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6134eabe-578f-4213-b9af-0bda6fe672c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import pickle \n",
    "#with open('preds_finetuned_augmented.pkl', 'rb') as f:\n",
    "#    predictions = pickle.load(f)\n",
    "#import pandas as pd \n",
    "#from langdetect import detect, LangDetectException\n",
    "#def detect_language(s):\n",
    "#    try:\n",
    "#        return detect(s)\n",
    "#    except LangDetectException:\n",
    "#        return \"unknown\"\n",
    "#test = pd.read_csv(\"./sentiment-analysis-test/data/val_clean.csv\")\n",
    "#test['lang'] = test['content'].apply(lambda x: detect_language(x))\n",
    "#LABEL_TO_ID = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "#true_labels = [LABEL_TO_ID[item] for item in test['sentiment'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca895c88-7aef-4c2f-a87d-6ce4959b2362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8458\n",
      "Accucary for negative: 0.838319541693189\n",
      "Accucary for neutral: 0.8906515580736544\n",
      "Accucary for positive: 0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(f'Accuracy: {accuracy_score(true_labels, predictions)}')\n",
    "matrix = confusion_matrix(true_labels, predictions)\n",
    "acc_classes = matrix.diagonal()/matrix.sum(axis=1)\n",
    "for i in range(len(acc_classes)):\n",
    "    print(f\"Accucary for {list(LABEL_TO_ID.keys())[i]}: {acc_classes[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ff4194f-148b-4137-a885-7dcbd2730bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:00, 1079559.35it/s]\n"
     ]
    }
   ],
   "source": [
    "data_lang_dic = {}\n",
    "from tqdm import tqdm\n",
    "for i, item in tqdm(enumerate(test.values)):\n",
    "    if item[2] not in data_lang_dic.keys():\n",
    "        data_lang_dic[item[2]] = []\n",
    "    data_lang_dic[item[2]].append([item[0], item[1], predictions[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7731edfe-978a-4c5b-a252-a87a9e1431ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_lang = []\n",
    "for k,v in data_lang_dic.items():\n",
    "    true_lab = [LABEL_TO_ID[item[1]] for item in v]\n",
    "    pred_lab = [item[2] for item in v]\n",
    "    matrix = confusion_matrix(true_lab, pred_lab)\n",
    "    #print(f\"For the language {k}: Accuracy is: {accuracy_score(true_lab, pred_lab)}\")\n",
    "    #print(f\"Accuracy per class is : {matrix.diagonal()/matrix.sum(axis=1)}\")\n",
    "    #print('---------------------------------------------------')\n",
    "    table_lang.append([k, accuracy_score(true_lab, pred_lab), matrix.diagonal()/matrix.sum(axis=1), len(v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5b3482b-46c3-41f5-aef8-a926b875e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_lang_sorted = sorted(table_lang, key=lambda k: -k[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a78658d-faa2-416d-8099-0e4947bccf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>acc per class</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>[0.7953667953667953, 0.8557377049180328, 0.787...</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ru</td>\n",
       "      <td>0.937690</td>\n",
       "      <td>[0.9298245614035088, 0.9826839826839827, 0.902...</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>[0.8644859813084113, 0.9427312775330396, 0.771...</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ar</td>\n",
       "      <td>0.835735</td>\n",
       "      <td>[0.8157894736842105, 0.9148936170212766, 0.739...</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr</td>\n",
       "      <td>0.848185</td>\n",
       "      <td>[0.8775510204081632, 0.8817204301075269, 0.794...</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>es</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>[0.8390804597701149, 0.8518518518518519, 0.86]</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pt</td>\n",
       "      <td>0.892704</td>\n",
       "      <td>[0.9036144578313253, 0.8939393939393939, 0.880...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ko</td>\n",
       "      <td>0.753488</td>\n",
       "      <td>[0.8222222222222222, 0.6914893617021277, 0.789...</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zh-cn</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>[0.7941176470588235, 0.6290322580645161, 0.767...</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ja</td>\n",
       "      <td>0.907975</td>\n",
       "      <td>[0.8703703703703703, 0.9183673469387755, 0.933...</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lang  accuracy                                      acc per class  size\n",
       "0     en  0.814815  [0.7953667953667953, 0.8557377049180328, 0.787...   837\n",
       "1     ru  0.937690  [0.9298245614035088, 0.9826839826839827, 0.902...   658\n",
       "2     id  0.864865  [0.8644859813084113, 0.9427312775330396, 0.771...   629\n",
       "3     ar  0.835735  [0.8157894736842105, 0.9148936170212766, 0.739...   347\n",
       "4     fr  0.848185  [0.8775510204081632, 0.8817204301075269, 0.794...   303\n",
       "5     es  0.850746     [0.8390804597701149, 0.8518518518518519, 0.86]   268\n",
       "6     pt  0.892704  [0.9036144578313253, 0.8939393939393939, 0.880...   233\n",
       "7     ko  0.753488  [0.8222222222222222, 0.6914893617021277, 0.789...   215\n",
       "8  zh-cn  0.731183  [0.7941176470588235, 0.6290322580645161, 0.767...   186\n",
       "9     ja  0.907975  [0.8703703703703703, 0.9183673469387755, 0.933...   163"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_acc_df = pd.DataFrame(table_lang_sorted, columns= [\"lang\", \"accuracy\", \"acc per class\", \"size\"])\n",
    "lang_acc_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e75e13a4-8c16-4fd6-8be3-c6825e8f5291",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_acc_df.to_csv(\"accuracy_per_language_pretrained.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
